{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02170c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn matplotlib tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e73d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4573d169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras-tuner) (3.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (0.0.9)\n",
      "Requirement already satisfied: h5py in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras->keras-tuner) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->keras-tuner) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84d7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic[all] in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (0.8.40)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (2.1.4)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (1.7.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (4.1.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (4.67.1)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from bertopic[all]) (0.5.7)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from hdbscan>=0.8.29->bertopic[all]) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from hdbscan>=0.8.29->bertopic[all]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas>=1.1.5->bertopic[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas>=1.1.5->bertopic[all]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas>=1.1.5->bertopic[all]) (2025.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from plotly>=4.7.0->bertopic[all]) (1.38.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from plotly>=4.7.0->bertopic[all]) (24.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn>=1.0->bertopic[all]) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[all]) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[all]) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[all]) (0.31.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[all]) (9.5.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[all]) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tqdm>=4.41.1->bertopic[all]) (0.4.6)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from umap-learn>=0.5.0->bertopic[all]) (0.61.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from umap-learn>=0.5.0->bertopic[all]) (0.5.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2.32.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic[all]) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[all]) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: bertopic 0.17.0 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "pip install bertopic[all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06e50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0a194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm sentence-transformers torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d972deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from statsmodels) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\anaconda\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506b9f7",
   "metadata": {},
   "source": [
    "TCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"2\"\n",
    "#KALAU MAU PAKAI GPU\n",
    "#import tensorflow as tf\n",
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    print(\"âœ… GPU tersedia:\", gpus)\n",
    "#    try:\n",
    "#        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#    except RuntimeError as e:\n",
    "#        print(e)\n",
    "#else:\n",
    "#    print(\"âš ï¸ GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, concatenate, TimeDistributed, BatchNormalization, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PRICE_FEATURES = ['open', 'high', 'low', 'close', 'volume']\n",
    "aapl = pd.read_csv(\"AAPL_2020_2025.csv\")\n",
    "apple_df = pd.read_csv(\"apple_with_sentiment.csv\")\n",
    "\n",
    "for df in [aapl, apple_df]:\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def run_topic_pipeline(news_df):\n",
    "    embeddings = embedding_model.encode(news_df['content'].tolist(), show_progress_bar=True)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        calculate_probabilities=True,\n",
    "        min_topic_size=15,\n",
    "        low_memory=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(news_df['content'], embeddings)\n",
    "    news_df['topic_prob'] = [np.array(p) for p in probs]\n",
    "\n",
    "    num_topics = len(set(topics)) - (1 if -1 in topics else 0)\n",
    "    daily_topic_sent = {}\n",
    "    for date, group in news_df.groupby('date'):\n",
    "        topic_sent = np.zeros(num_topics)\n",
    "        topic_weight = np.zeros(num_topics)\n",
    "        for _, row in group.iterrows():\n",
    "            for i in range(num_topics):\n",
    "                topic_sent[i] += row['sentiment_score'] * row['topic_prob'][i]\n",
    "                topic_weight[i] += row['topic_prob'][i]\n",
    "        avg_sent = [topic_sent[i]/topic_weight[i] if topic_weight[i]!=0 else 0 for i in range(num_topics)]\n",
    "        daily_topic_sent[date] = avg_sent\n",
    "\n",
    "    sent_df = pd.DataFrame.from_dict(daily_topic_sent, orient='index')\n",
    "    sent_df.index = pd.to_datetime(sent_df.index).tz_localize(None).normalize()\n",
    "    return sent_df\n",
    "\n",
    "topic_aapl = run_topic_pipeline(apple_df)\n",
    "\n",
    "def merge_price_topic(stock_df, topic_df):\n",
    "    df = stock_df.copy()\n",
    "    df = df[df['date'] >= '2021-01-01']\n",
    "    df.set_index('date', inplace=True)\n",
    "    return pd.merge(df, topic_df, left_index=True, right_index=True, how='inner').dropna()\n",
    "\n",
    "merged_aapl = merge_price_topic(aapl, topic_aapl)\n",
    "WINDOW_SIZE = 360\n",
    "\n",
    "def make_dataset(df, window_size):\n",
    "    X_price, X_topic, y, dates = [], [], [], []\n",
    "    scaler = StandardScaler()\n",
    "    scaled_prices = scaler.fit_transform(df[PRICE_FEATURES])\n",
    "    for i in range(window_size, len(df) - 1):\n",
    "        price = scaled_prices[i-window_size:i]\n",
    "        topic = df.iloc[i-window_size:i, len(PRICE_FEATURES):].to_numpy(dtype=np.float32)\n",
    "        target = df.iloc[i+1]['close']\n",
    "        date = df.index[i+1]\n",
    "        X_price.append(price)\n",
    "        X_topic.append(topic)\n",
    "        y.append(target)\n",
    "        dates.append(date)\n",
    "    return (\n",
    "        np.array(X_price, dtype=np.float32),\n",
    "        np.array(X_topic, dtype=np.float32),\n",
    "        np.array(y, dtype=np.float32),\n",
    "        dates\n",
    "    )\n",
    "\n",
    "Xp, Xt, y, y_dates = make_dataset(merged_aapl, WINDOW_SIZE)\n",
    "\n",
    "def build_tcnn_model(Xp, Xt):\n",
    "    in_price = Input(shape=(Xp.shape[1], Xp.shape[2]))\n",
    "    x1 = Conv1D(64, kernel_size=3, activation='relu')(in_price)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, activation='relu')(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    in_topic = Input(shape=(Xt.shape[1], Xt.shape[2]))\n",
    "    x2 = TimeDistributed(Dense(64, activation='relu'))(in_topic)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = TimeDistributed(Dense(32, activation='relu'))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "    x = concatenate([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[in_price, in_topic], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "from tqdm import tqdm\n",
    "def walk_forward_tcnn(Xp, Xt, y, dates, start=0.8):\n",
    "    n_total = len(y)\n",
    "    n_train = int(n_total * start)\n",
    "    y_pred, y_true = [], []\n",
    "    start_all = time.time()\n",
    "    for i in tqdm(range(n_train, n_total), desc=\"Walk-Forward TCNN\"):\n",
    "        t0 = time.time()\n",
    "        model = build_tcnn_model(Xp, Xt)\n",
    "        model.fit([Xp[:i], Xt[:i]], y[:i], epochs=30, batch_size=32, verbose=0)\n",
    "        pred = model.predict([Xp[i:i+1], Xt[i:i+1]], verbose=0)[0][0]\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y[i])\n",
    "        t1 = time.time()\n",
    "        print(f\"Step {i}/{n_total} - Time: {t1 - t0:.2f}s\")\n",
    "    print(f\"Total time: {(time.time() - start_all)/60:.2f} minutes\")\n",
    "    return y_true, y_pred\n",
    "\n",
    "def evaluate_baseline(y_true, y_pred, label=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"ðŸ“Š {label} â€” MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.4f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "def baseline_random_walk(y_true):\n",
    "    return y_true[:-1], y_true[1:]\n",
    "\n",
    "def baseline_arima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = ARIMA(history, order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        predictions.append(output[0])\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "def baseline_sarima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = SARIMAX(history, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "print(\"\\nðŸ” Training TCNN with Walk-Forward Validation + ETA...\")\n",
    "y_true_tcnn, y_pred_tcnn = walk_forward_tcnn(Xp, Xt, y, y_dates)\n",
    "evaluate_baseline(y_true_tcnn, y_pred_tcnn, \"TCNN\")\n",
    "\n",
    "print(\"\\nðŸ“‰ Evaluating Baseline Models...\")\n",
    "y_rw_true, y_rw_pred = baseline_random_walk(list(y))\n",
    "evaluate_baseline(y_rw_true, y_rw_pred, \"Random Walk\")\n",
    "\n",
    "y_arima_true, y_arima_pred = baseline_arima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_arima_true, y_arima_pred, \"ARIMA\")\n",
    "\n",
    "y_sarima_true, y_sarima_pred = baseline_sarima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_sarima_true, y_sarima_pred, \"SARIMA\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_true_tcnn[:100], label=\"Actual\", marker='o')\n",
    "plt.plot(y_pred_tcnn[:100], label=\"TCNN Predicted\", marker='x')\n",
    "plt.title(\"AAPL - TCNN Walk-Forward Prediction (First 100 Days)\")\n",
    "plt.legend(); plt.grid(); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ðŸ’¾ Simpan prediksi untuk uji statistik\n",
    "np.save(\"y_pred_tcnn.npy\", np.array(y_pred_tcnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410013d",
   "metadata": {},
   "source": [
    "Versi coba tanpa Retracing / Loopnya di luar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCNN with optimized walk-forward (no retracing on predict)\n",
    "#KALAU MAU PAKAI GPU\n",
    "#import tensorflow as tf\n",
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    print(\"âœ… GPU tersedia:\", gpus)\n",
    "#    try:\n",
    "#        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#    except RuntimeError as e:\n",
    "#        print(e)\n",
    "#else:\n",
    "#    print(\"âš ï¸ GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, concatenate, TimeDistributed, BatchNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PRICE_FEATURES = ['open', 'high', 'low', 'close', 'volume']\n",
    "aapl = pd.read_csv(\"AAPL_2020_2025.csv\")\n",
    "apple_df = pd.read_csv(\"apple_with_sentiment.csv\")\n",
    "\n",
    "for df in [aapl, apple_df]:\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def run_topic_pipeline(news_df):\n",
    "    embeddings = embedding_model.encode(news_df['content'].tolist(), show_progress_bar=True)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        calculate_probabilities=True,\n",
    "        min_topic_size=15,\n",
    "        low_memory=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(news_df['content'], embeddings)\n",
    "    news_df['topic_prob'] = [np.array(p) for p in probs]\n",
    "\n",
    "    num_topics = len(set(topics)) - (1 if -1 in topics else 0)\n",
    "    daily_topic_sent = {}\n",
    "    for date, group in news_df.groupby('date'):\n",
    "        topic_sent = np.zeros(num_topics)\n",
    "        topic_weight = np.zeros(num_topics)\n",
    "        for _, row in group.iterrows():\n",
    "            for i in range(num_topics):\n",
    "                topic_sent[i] += row['sentiment_score'] * row['topic_prob'][i]\n",
    "                topic_weight[i] += row['topic_prob'][i]\n",
    "        avg_sent = [topic_sent[i]/topic_weight[i] if topic_weight[i]!=0 else 0 for i in range(num_topics)]\n",
    "        daily_topic_sent[date] = avg_sent\n",
    "\n",
    "    sent_df = pd.DataFrame.from_dict(daily_topic_sent, orient='index')\n",
    "    sent_df.index = pd.to_datetime(sent_df.index).tz_localize(None).normalize()\n",
    "    return sent_df\n",
    "\n",
    "topic_aapl = run_topic_pipeline(apple_df)\n",
    "\n",
    "def merge_price_topic(stock_df, topic_df):\n",
    "    df = stock_df.copy()\n",
    "    df = df[df['date'] >= '2021-01-01']\n",
    "    df.set_index('date', inplace=True)\n",
    "    return pd.merge(df, topic_df, left_index=True, right_index=True, how='inner').dropna()\n",
    "\n",
    "merged_aapl = merge_price_topic(aapl, topic_aapl)\n",
    "WINDOW_SIZE = 360\n",
    "\n",
    "def make_dataset(df, window_size):\n",
    "    X_price, X_topic, y, dates = [], [], [], []\n",
    "    scaler = StandardScaler()\n",
    "    scaled_prices = scaler.fit_transform(df[PRICE_FEATURES])\n",
    "    for i in range(window_size, len(df) - 1):\n",
    "        price = scaled_prices[i-window_size:i]\n",
    "        topic = df.iloc[i-window_size:i, len(PRICE_FEATURES):].to_numpy(dtype=np.float32)\n",
    "        target = df.iloc[i+1]['close']\n",
    "        date = df.index[i+1]\n",
    "        X_price.append(price)\n",
    "        X_topic.append(topic)\n",
    "        y.append(target)\n",
    "        dates.append(date)\n",
    "    return (\n",
    "        np.array(X_price, dtype=np.float32),\n",
    "        np.array(X_topic, dtype=np.float32),\n",
    "        np.array(y, dtype=np.float32),\n",
    "        dates\n",
    "    )\n",
    "\n",
    "Xp, Xt, y, y_dates = make_dataset(merged_aapl, WINDOW_SIZE)\n",
    "\n",
    "def build_tcnn_model(Xp, Xt):\n",
    "    in_price = Input(shape=(Xp.shape[1], Xp.shape[2]))\n",
    "    x1 = Conv1D(64, kernel_size=3, activation='relu')(in_price)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, activation='relu')(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    in_topic = Input(shape=(Xt.shape[1], Xt.shape[2]))\n",
    "    x2 = TimeDistributed(Dense(64, activation='relu'))(in_topic)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = TimeDistributed(Dense(32, activation='relu'))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "    x = concatenate([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[in_price, in_topic], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "def walk_forward_tcnn_no_retrace(Xp, Xt, y, dates, start=0.8, epochs=10):\n",
    "    n_total = len(y)\n",
    "    n_train = int(n_total * start)\n",
    "    y_pred, y_true = [], []\n",
    "    start_all = time.time()\n",
    "    model = build_tcnn_model(Xp, Xt)\n",
    "    for i in tqdm(range(n_train, n_total), desc=\"Walk-Forward TCNN (No Retrace)\"):\n",
    "        t0 = time.time()\n",
    "        model.fit([Xp[:i], Xt[:i]], y[:i], epochs=epochs, batch_size=32, verbose=0)\n",
    "        pred = model.predict([Xp[i:i+1], Xt[i:i+1]], verbose=0)[0][0]\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y[i])\n",
    "        print(f\"Step {i}/{n_total} - Time: {time.time() - t0:.2f}s\")\n",
    "    print(f\"Total time: {(time.time() - start_all)/60:.2f} minutes\")\n",
    "    return y_true, y_pred\n",
    "\n",
    "def evaluate_baseline(y_true, y_pred, label=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"ðŸ“Š {label} â€” MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.4f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "def baseline_random_walk(y_true):\n",
    "    return y_true[:-1], y_true[1:]\n",
    "\n",
    "def baseline_arima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = ARIMA(history, order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        predictions.append(output[0])\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "def baseline_sarima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = SARIMAX(history, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "print(\"\\nðŸ” Training TCNN with Walk-Forward Validation (No Retrace)...\")\n",
    "y_true_tcnn, y_pred_tcnn = walk_forward_tcnn_no_retrace(Xp, Xt, y, y_dates)\n",
    "evaluate_baseline(y_true_tcnn, y_pred_tcnn, \"TCNN\")\n",
    "\n",
    "print(\"\\nðŸ“‰ Evaluating Baseline Models...\")\n",
    "y_rw_true, y_rw_pred = baseline_random_walk(list(y))\n",
    "evaluate_baseline(y_rw_true, y_rw_pred, \"Random Walk\")\n",
    "\n",
    "y_arima_true, y_arima_pred = baseline_arima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_arima_true, y_arima_pred, \"ARIMA\")\n",
    "\n",
    "y_sarima_true, y_sarima_pred = baseline_sarima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_sarima_true, y_sarima_pred, \"SARIMA\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_true_tcnn[:100], label=\"Actual\", marker='o')\n",
    "plt.plot(y_pred_tcnn[:100], label=\"TCNN Predicted\", marker='x')\n",
    "plt.title(\"AAPL - TCNN Walk-Forward Prediction (First 100 Days)\")\n",
    "plt.legend(); plt.grid(); plt.show()\n",
    "\n",
    "# ðŸ’¾ Simpan prediksi untuk uji statistik\n",
    "np.save(\"y_pred_tcnn.npy\", np.array(y_pred_tcnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc4f4d",
   "metadata": {},
   "source": [
    "Versi Pakai Expanding Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCNN with expanding-window validation (step=5) + baselines + metrics + plot\n",
    "#KALAU MAU PAKAI GPU\n",
    "#import tensorflow as tf\n",
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    print(\"âœ… GPU tersedia:\", gpus)\n",
    "#    try:\n",
    "#        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#    except RuntimeError as e:\n",
    "#        print(e)\n",
    "#else:\n",
    "#    print(\"âš ï¸ GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, concatenate, TimeDistributed, BatchNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "PRICE_FEATURES = ['open', 'high', 'low', 'close', 'volume']\n",
    "aapl = pd.read_csv(\"AAPL_2020_2025.csv\")\n",
    "apple_df = pd.read_csv(\"apple_with_sentiment.csv\")\n",
    "for df in [aapl, apple_df]:\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "# Topic modeling pipeline\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def run_topic_pipeline(news_df):\n",
    "    embeddings = embedding_model.encode(news_df['content'].tolist(), show_progress_bar=True)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        calculate_probabilities=True,\n",
    "        min_topic_size=15,\n",
    "        low_memory=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(news_df['content'], embeddings)\n",
    "    news_df['topic_prob'] = [np.array(p) for p in probs]\n",
    "    num_topics = len(set(topics)) - (1 if -1 in topics else 0)\n",
    "\n",
    "    daily_topic_sent = {}\n",
    "    for date, group in news_df.groupby('date'):\n",
    "        topic_sent = np.zeros(num_topics)\n",
    "        topic_weight = np.zeros(num_topics)\n",
    "        for _, row in group.iterrows():\n",
    "            for i in range(num_topics):\n",
    "                topic_sent[i] += row['sentiment_score'] * row['topic_prob'][i]\n",
    "                topic_weight[i] += row['topic_prob'][i]\n",
    "        avg_sent = [topic_sent[i]/topic_weight[i] if topic_weight[i]!=0 else 0 for i in range(num_topics)]\n",
    "        daily_topic_sent[date] = avg_sent\n",
    "\n",
    "    sent_df = pd.DataFrame.from_dict(daily_topic_sent, orient='index')\n",
    "    sent_df.index = pd.to_datetime(sent_df.index).tz_localize(None).normalize()\n",
    "    return sent_df\n",
    "\n",
    "topic_aapl = run_topic_pipeline(apple_df)\n",
    "\n",
    "def merge_price_topic(stock_df, topic_df):\n",
    "    df = stock_df.copy()\n",
    "    df = df[df['date'] >= '2021-01-01']\n",
    "    df.set_index('date', inplace=True)\n",
    "    return pd.merge(df, topic_df, left_index=True, right_index=True, how='inner').dropna()\n",
    "\n",
    "merged_aapl = merge_price_topic(aapl, topic_aapl)\n",
    "WINDOW_SIZE = 360\n",
    "\n",
    "def make_dataset(df, window_size):\n",
    "    X_price, X_topic, y, dates = [], [], [], []\n",
    "    scaler = StandardScaler()\n",
    "    scaled_prices = scaler.fit_transform(df[PRICE_FEATURES])\n",
    "    for i in range(window_size, len(df) - 1):\n",
    "        price = scaled_prices[i-window_size:i]\n",
    "        topic = df.iloc[i-window_size:i, len(PRICE_FEATURES):].to_numpy(dtype=np.float32)\n",
    "        target = df.iloc[i+1]['close']\n",
    "        date = df.index[i+1]\n",
    "        X_price.append(price)\n",
    "        X_topic.append(topic)\n",
    "        y.append(target)\n",
    "        dates.append(date)\n",
    "    return (\n",
    "        np.array(X_price, dtype=np.float32),\n",
    "        np.array(X_topic, dtype=np.float32),\n",
    "        np.array(y, dtype=np.float32),\n",
    "        dates\n",
    "    )\n",
    "\n",
    "Xp, Xt, y, y_dates = make_dataset(merged_aapl, WINDOW_SIZE)\n",
    "\n",
    "# Build TCNN model\n",
    "def build_tcnn_model(Xp, Xt):\n",
    "    in_price = Input(shape=(Xp.shape[1], Xp.shape[2]))\n",
    "    x1 = Conv1D(filters=64, kernel_size=3, activation='relu')(in_price)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Conv1D(filters=32, kernel_size=3, activation='relu')(x1)\n",
    "    x1 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "    in_topic = Input(shape=(Xt.shape[1], Xt.shape[2]))\n",
    "    x2 = TimeDistributed(Dense(64, activation='relu'))(in_topic)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = TimeDistributed(Dense(32, activation='relu'))(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    x2 = GlobalAveragePooling1D()(x2)\n",
    "\n",
    "    x = concatenate([x1, x2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[in_price, in_topic], outputs=out)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Expanding-window validation\n",
    "def walk_forward_tcnn_expanding_step5(Xp, Xt, y, dates, start=0.8, epochs=10):\n",
    "    n_total = len(y)\n",
    "    n_train = int(n_total * start)\n",
    "    y_pred, y_true = [], []\n",
    "    model = build_tcnn_model(Xp, Xt)\n",
    "\n",
    "    step_durations = []\n",
    "    for i in tqdm(range(n_train, n_total, 5), desc=\"Expanding Step=5\"):\n",
    "        start_time = time.time()\n",
    "        model.fit([Xp[:i], Xt[:i]], y[:i], epochs=epochs, batch_size=32, verbose=0)\n",
    "        for j in range(i, min(i+5, n_total)):\n",
    "            pred = model.predict([Xp[j:j+1], Xt[j:j+1]], verbose=0)[0][0]\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(y[j])\n",
    "        step_time = time.time() - start_time\n",
    "        avg_time = np.mean(step_durations) if step_durations else 0\n",
    "        eta = ((n_total - i - 1) // 5 * avg_time) / 60 if avg_time else 0\n",
    "        step_durations.append(step_time)\n",
    "        print(f\"Step {i}-{min(i+5, n_total)-1} done in {step_time:.2f}s | ETA: {eta:.2f} min\")\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_baseline(y_true, y_pred, label=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"ðŸ“Š {label} â€” MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.4f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Baseline models\n",
    "def baseline_random_walk(y_true):\n",
    "    return y_true[:-1], y_true[1:]\n",
    "\n",
    "def baseline_arima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = ARIMA(history, order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "        predictions.append(model_fit.forecast()[0])\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "def baseline_sarima(df_close):\n",
    "    history = list(df_close[:WINDOW_SIZE])\n",
    "    predictions = []\n",
    "    for t in range(WINDOW_SIZE, len(df_close)-1):\n",
    "        model = SARIMAX(history, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        predictions.append(model_fit.forecast()[0])\n",
    "        history.append(df_close[t])\n",
    "    return df_close[WINDOW_SIZE+1:], predictions[1:]\n",
    "\n",
    "# Run training and evaluation\n",
    "print(\"\\nðŸ” Training TCNN with Expanding Step=5...\")\n",
    "y_true_tcnn, y_pred_tcnn = walk_forward_tcnn_expanding_step5(Xp, Xt, y, y_dates)\n",
    "\n",
    "np.save(\"y_true_tcnn_step5.npy\", np.array(y_true_tcnn))\n",
    "np.save(\"y_pred_tcnn_step5.npy\", np.array(y_pred_tcnn))\n",
    "\n",
    "evaluate_baseline(y_true_tcnn, y_pred_tcnn, \"TCNN (Step=5)\")\n",
    "\n",
    "print(\"\\nðŸ“‰ Evaluating Baseline Models...\")\n",
    "y_rw_true, y_rw_pred = baseline_random_walk(list(y))\n",
    "evaluate_baseline(y_rw_true, y_rw_pred, \"Random Walk\")\n",
    "\n",
    "y_arima_true, y_arima_pred = baseline_arima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_arima_true, y_arima_pred, \"ARIMA\")\n",
    "\n",
    "y_sarima_true, y_sarima_pred = baseline_sarima(list(merged_aapl['close'].values))\n",
    "evaluate_baseline(y_sarima_true, y_sarima_pred, \"SARIMA\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_true_tcnn[:100], label=\"Actual\", marker='o')\n",
    "plt.plot(y_pred_tcnn[:100], label=\"TCNN Predicted\", marker='x')\n",
    "plt.title(\"AAPL - TCNN Expanding Step=5 Prediction (First 100 Days)\")\n",
    "plt.legend(); plt.grid(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
